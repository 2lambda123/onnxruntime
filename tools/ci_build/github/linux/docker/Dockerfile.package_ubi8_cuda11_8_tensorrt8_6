# --------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
# --------------------------------------------------------------
# Dockerfile to run ONNXRuntime with TensorRT integration

# Build base image with required system packages
FROM nvidia/cuda:11.8.0-cudnn8-devel-ubi8 AS base

# The local directory into which to build and install CMAKE
ARG ONNXRUNTIME_LOCAL_CODE_DIR=/code

ENV PATH /usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/src/tensorrt/bin:${PATH}

RUN dnf update -y &&\
    dnf install -y bash wget

# Install python3
RUN dnf install -y \
    python3 \
    python3-pip \
    python3-wheel &&\
    cd /usr/local/bin &&\
    ln -s /usr/bin/python3 python &&\
    ln -s /usr/bin/pip3 pip;

RUN pip install --upgrade pip
RUN pip install setuptools>=41.0.0

# Install TensorRT
RUN v="8.6.1.6-1+cuda11.8" &&\
    yum downgrade tensorrt-devel-${version} tensorrt-${version} -y &&\
    yum install yum-plugin-versionlock -y &&\
    yum versionlock tensorrt-devel-${version} tensorrt-${version}

RUN dnf clean dbcache

ADD scripts /tmp/scripts
RUN cd /tmp/scripts && /tmp/scripts/install_dotnet.sh && /tmp/scripts/install_java.sh && rm -rf /tmp/scripts

# Build final image from base.
FROM base as final
ARG BUILD_USER=onnxruntimedev
ARG BUILD_UID=1000
RUN adduser --uid $BUILD_UID $BUILD_USER
WORKDIR /home/$BUILD_USER
USER $BUILD_USER
